<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>YOLOv8 Object Detection</title>
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
    <style>
body, html {
    margin: 0;
            padding: 0;
}

#rightVideoContainer {
    width: 100%;
            height: 100%;
            object-fit: cover;
            /* Cover the area without changing aspect ratio */
            position: absolute;
            top: 0;
            left: 0;
}

canvas, video {
    width: 100%;
            height: 100%;
            object-fit: cover;
            /* Cover the area without changing aspect ratio */
            position: absolute;
            top: 0;
            left: 0;
}

#videoFeed {
    display: none;
}

    </style>
</head>

<body>
    <video id="videoFeed" autoplay playsinline ></video>
    <div id="rightVideoContainer" >
        <video id="simpleVideoFeed" autoplay playsinline ></video>
        <canvas ></canvas>
    </div>
    <script>
        const video = document.getElementById('videoFeed');
        const canvas = document.querySelector('canvas');
        const ctx = canvas.getContext('2d');
        let model = null;

        // Function to start the video stream
        async function startVideo() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment',
                        width: {ideal:1920},
                        height: {ideal:1080}
                    }
                });
                video.srcObject = stream;
            } catch (error) {
                console.error('Error accessing the camera:', error);
            }
        }

        video.addEventListener('loadedmetadata', () => {
            processVideo();
        });

        async function processVideo() {
            if (video.readyState === 4) {
                // Cropping the center 640x640 region from the video frame
                ctx.drawImage(video, (video.videoWidth - 640) / 2, (video.videoHeight - 640) / 2, 640, 640, 0, 0, 640, 640);
                const imgData = ctx.getImageData(0, 0, 640, 640);

                const boxes = await detect_objects_on_image(imgData);
                draw_boxes(boxes);
            }
            requestAnimationFrame(processVideo);
        }

        // Initialize your YOLO model here
        async function loadModel() {
            // Load your model
            model = await ort.InferenceSession.create("best.onnx");
        }

        async function detect_objects_on_image(imgData) {
            const input = prepare_input(imgData);
            const output = await run_model(input);
            return process_output(output, 1920, 1080);
        }

        function prepare_input(imgData) {
            const pixels = imgData.data;
            const red = [], green = [], blue = [];
            for (let i = 0; i < pixels.length; i += 4) {
                red.push(pixels[i] / 255.0);
                green.push(pixels[i + 1] / 255.0);
                blue.push(pixels[i + 2] / 255.0);
            }
            return [...red, ...green, ...blue];
        }

        async function run_model(input) {
            // Adjust the tensor dimensions to match the image data
            const inputTensor = new ort.Tensor(Float32Array.from(input), [1, 3, 640, 640]);
            const outputs = await model.run({ images: inputTensor });
            console.log(outputs["output0"].data);
            return outputs["output0"].data;
        }

        function process_output(output, img_width, img_height) {
            let boxes = [];
            for (let index = 0; index < 8400; index++) {
                const [class_id, prob] = [...Array(80).keys()]
                    .map(col => [col, output[8400 * (col + 4) + index]])
                    .reduce((accum, item) => item[1] > accum[1] ? item : accum, [0, 0]);
                if (prob < 0.5) {
                    continue;
                }
                const label = yolo_classes[class_id];
                const xc = output[index];
                const yc = output[8400 + index];
                const w = output[2 * 8400 + index];
                const h = output[3 * 8400 + index];
                const x1 = (xc - w / 2) / 640 * img_width;
                const y1 = (yc - h / 2) / 640 * img_height;
                const x2 = (xc + w / 2) / 640 * img_width;
                const y2 = (yc + h / 2) / 640 * img_height;
                boxes.push([x1, y1, x2, y2, label, prob]);
            }

            boxes = boxes.sort((box1, box2) => box2[5] - box1[5])
            const result = [];
            while (boxes.length > 0) {
                result.push(boxes[0]);
                boxes = boxes.filter(box => iou(boxes[0], box) < 0.7);
            }
            return result;
        }

        function iou(box1, box2) {
            return intersection(box1, box2) / union(box1, box2);
        }

        function union(box1, box2) {
            const [box1_x1, box1_y1, box1_x2, box1_y2] = box1;
            const [box2_x1, box2_y1, box2_x2, box2_y2] = box2;
            const box1_area = (box1_x2 - box1_x1) * (box1_y2 - box1_y1)
            const box2_area = (box2_x2 - box2_x1) * (box2_y2 - box2_y1)
            return box1_area + box2_area - intersection(box1, box2)
        }

        function intersection(box1, box2) {
            const [box1_x1, box1_y1, box1_x2, box1_y2] = box1;
            const [box2_x1, box2_y1, box2_x2, box2_y2] = box2;
            const x1 = Math.max(box1_x1, box2_x1);
            const y1 = Math.max(box1_y1, box2_y1);
            const x2 = Math.min(box1_x2, box2_x2);
            const y2 = Math.min(box1_y2, box2_y2);
            return (x2 - x1) * (y2 - y1)
        }

function draw_boxes(boxes) {
    // Clear previous drawings
    ctx.clearRect(0, 0, canvas.width, canvas.height); 

    // Do not draw the video frame from videoFeed, only draw boxes
    ctx.strokeStyle = "#00FF00";
    ctx.lineWidth = 3;
    ctx.font = "18px serif";

    boxes.forEach(([x1, y1, x2, y2, label]) => {
        // Draw bounding box
        ctx.strokeRect(x1, y1, x2 - x1, y2 - y1);

        // Draw label background
        ctx.fillStyle = "#00ff00";
        const width = ctx.measureText(label).width;
        ctx.fillRect(x1, y1 - 25, width + 10, 25);

        // Draw label text
        ctx.fillStyle = "#000000";
        ctx.fillText(label, x1 + 5, y1 - 5);
    });
}

        const yolo_classes = ['tablo'];

        // Function to start the second video stream
async function startSimpleVideo() {
    try {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: {
                facingMode: 'environment',
            }
        });
        document.getElementById('simpleVideoFeed').srcObject = stream;
    } catch (error) {
        console.error('Error accessing the camera for simple video:', error);
    }
}

// Start the second video feed


        // Load the model and start the video
        loadModel();
        startVideo();
        startSimpleVideo();


    </script>
</body>

</html>
